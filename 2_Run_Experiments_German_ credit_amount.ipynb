{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "# LDP import\n",
    "from multi_freq_ldpy.pure_frequency_oracles.GRR import GRR_Client\n",
    "from GRR import GRR_Client\n",
    "# Fairness imports\n",
    "from GroupFairnessNotions import confusion_matrix_scorer, Statistical_parity, Metric_disparity, Equal_opportunity, Predictive_equality, Treatment_equality, Overall_accuracy, Predictive_rate_parity, CSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_seed = 100\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "# Reading dataset\n",
    "#dataset = 'german_2024' \n",
    "dataset = 'german_good_outcome' \n",
    "#dataset = 'german_good_outcome'\n",
    "# Target attribute\n",
    "target = 'default' \n",
    "\n",
    "# Protected attribute \n",
    "protected_att = 'personal_status_sex'\n",
    "\n",
    "\n",
    "# Folder where results are saved as csv files\n",
    "results_path = 'Results/Accuracy/'\n",
    "# Fariness metrics and info no privacy results\n",
    "header_nldp = [\"Seed_num\",\"SP_maj\", \"SP_min\", \"SPD\",\"EO_maj\",\"EO_min\",\"EOD\",\"CSP_X0_maj\", \"CSP_X0_min\", \"CSD_X0\",\"CSP_X1_maj\", \"CSP_X1_min\", \"CSD_X1\",\"Accuracy\"]\n",
    "# Fariness metrics and info for privacy settings\n",
    "header_ldp = [\"Seed_num\",\"epsilon\",\"SP_maj\", \"SP_min\", \"SPD\",\"EO_maj\",\"EO_min\",\"EOD\",\"CSP_X0_maj\", \"CSP_X0_min\", \"CSD_X0\",\"CSP_X1_maj\", \"CSP_X1_min\", \"CSD_X1\",\"Accuracy\"]\n",
    "\n",
    "# Epsilon values for privacy\n",
    "lst_eps = [50,16,8,5,4,3,2,1,0.5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to csv function for saving the results\n",
    "def write_to_csv(setting,dataset,header):\n",
    "    with open(results_path + dataset + '_'+ setting +'_results_median.csv', mode='a', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)    \n",
    "        writer.writerow(header)   \n",
    "    file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/Real_data/German_credit/' + dataset + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1000.000000\n",
       "mean      3271.258000\n",
       "std       2822.736876\n",
       "min        250.000000\n",
       "25%       1365.500000\n",
       "50%       2319.500000\n",
       "75%       3972.250000\n",
       "max      18424.000000\n",
       "Name: credit_amount, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.credit_amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credit_amount'] = np.where(df['credit_amount'] > df.credit_amount.median(), 1, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    700\n",
      "0    300\n",
      "Name: default, dtype: int64\n",
      "A0_Y0: 109\n",
      " A0_Y1: 201\n",
      " A1_Y0: 191\n",
      " A1_Y1: 499\n"
     ]
    }
   ],
   "source": [
    "print(df.default.value_counts())\n",
    "A0_Y0 = len(df[(df['personal_status_sex'] == 0) & (df['default'] == 0)])\n",
    "A0_Y1 = len(df[(df['personal_status_sex'] == 0) & (df['default'] == 1)])\n",
    "A1_Y0 = len(df[(df['personal_status_sex'] == 1) & (df['default'] == 0)])\n",
    "A1_Y1 = len(df[(df['personal_status_sex'] == 1) & (df['default'] == 1)])\n",
    "print(f'A0_Y0: {A0_Y0}\\n A0_Y1: {A0_Y1}\\n A1_Y0: {A1_Y0}\\n A1_Y1: {A1_Y1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    500\n",
       "Name: credit_amount, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.credit_amount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0_X0_Y0: 0.059\n",
      "\n",
      "A0_X1_Y0: 0.05\n",
      "\n",
      "A1_X0_Y0: 0.08\n",
      "\n",
      "A1_X1_Y0: 0.111\n",
      "\n",
      "A0_X0_Y1: 0.12\n",
      "\n",
      "A0_X1_Y1: 0.081\n",
      "\n",
      "A1_X0_Y1: 0.241\n",
      "\n",
      "A1_X1_Y1: 0.258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A0_X0_Y0 = len(df[(df['personal_status_sex'] == 0) & (df['credit_amount'] == 0) & (df['default'] == 0)])\n",
    "A0_X1_Y0 = len(df[(df['personal_status_sex'] == 0) & (df['credit_amount'] == 1) & (df['default'] == 0)])\n",
    "\n",
    "A1_X0_Y0 = len(df[(df['personal_status_sex'] == 1) & (df['credit_amount'] == 0) & (df['default'] == 0)])\n",
    "A1_X1_Y0 = len(df[(df['personal_status_sex'] == 1) & (df['credit_amount'] == 1) & (df['default'] == 0)])\n",
    "\n",
    "A0_X0_Y1 = len(df[(df['personal_status_sex'] == 0) & (df['credit_amount'] == 0) & (df['default'] == 1)])\n",
    "A0_X1_Y1 = len(df[(df['personal_status_sex'] == 0) & (df['credit_amount'] == 1) & (df['default'] == 1)])\n",
    "\n",
    "A1_X0_Y1 = len(df[(df['personal_status_sex'] == 1) & (df['credit_amount'] == 0) & (df['default'] == 1)])\n",
    "A1_X1_Y1 = len(df[(df['personal_status_sex'] == 1) & (df['credit_amount'] == 1) & (df['default'] == 1)])\n",
    "\n",
    "print(f'A0_X0_Y0: {A0_X0_Y0/1000}\\n') \n",
    "print(f'A0_X1_Y0: {A0_X1_Y0/1000}\\n') \n",
    "print(f'A1_X0_Y0: {A1_X0_Y0/1000}\\n') \n",
    "print(f'A1_X1_Y0: {A1_X1_Y0/1000}\\n') \n",
    "print(f'A0_X0_Y1: {A0_X0_Y1/1000}\\n') \n",
    "print(f'A0_X1_Y1: {A0_X1_Y1/1000}\\n') \n",
    "print(f'A1_X0_Y1: {A1_X0_Y1/1000}\\n') \n",
    "print(f'A1_X1_Y1: {A1_X1_Y1/1000}\\n')\n",
    "\n",
    "\n",
    "l = [A0_X0_Y0,A0_X1_Y0,A1_X0_Y0,A1_X1_Y0,A0_X0_Y1,A0_X1_Y1,A1_X0_Y1,A1_X1_Y1]\n",
    "x = sum(l)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for no privacy setting (baseline setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "That took 104.36763119697571 seconds\n"
     ]
    }
   ],
   "source": [
    "#folder_name of the results\n",
    "setting = 'NoLDP'\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "# write head of csv file\n",
    "write_to_csv(setting,dataset,header_nldp)\n",
    "\n",
    "df_cp = copy.deepcopy(df)\n",
    "\n",
    "\n",
    "np_sp_min1, np_sp_maj1, np_sd = [], [], []\n",
    "ndp_csp_minX0, ndp_csp_majX0, np_csd_X0, ndp_csp_minX1, ndp_csp_majX1, np_csd_X1 = [], [] ,[] , [],[], []\n",
    "np_eo_min1, np_eo_maj1, np_eod, acc = [], [], [], []\n",
    "\n",
    "\n",
    "for seed in range(nb_seed):\n",
    "    print(seed)\n",
    "    np.random.seed(seed) # for reproducibility\n",
    "    \n",
    "    # Use original datasets\n",
    "    X = copy.deepcopy(df_cp.drop(target, axis=1))\n",
    "    y = copy.deepcopy(df_cp[target])\n",
    "\n",
    "    # Train test splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True, stratify=y, random_state=seed)\n",
    "    \n",
    "    # instantiate and train model\n",
    "    model = RandomForestClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # accuracy\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "    # retrieving minority, majority from the test set\n",
    "    X_test_min, X_test_maj = X_test[X_test[protected_att] == 0], X_test[X_test[protected_att] == 1]\n",
    "\n",
    "    # predicted outcomes for minority, majority\n",
    "    y_pred_min, y_pred_maj = model.predict(X_test_min), model.predict(X_test_maj)\n",
    "\n",
    "    indices_min, indices_maj = X_test_min.index, X_test_maj.index\n",
    "    y_test_min, y_test_maj = y_test.get(key = indices_min), y_test.get(key = indices_maj)\n",
    "    \n",
    "    # Needed for the computation of Cond.Stat.Disp\n",
    "            \n",
    "    # retrieving four groups: A=0_X=0, A0_X=1, A1_X=0, A1_X=1 from the test set\n",
    "\n",
    "    X_test_min_X0, X_test_min_X1, X_test_maj_X0, X_test_maj_X1 = X_test[(X_test[protected_att] == 0) & (X_test['credit_amount'] == 0)], X_test[(X_test[protected_att] == 0) & (X_test['credit_amount'] == 1)], X_test[(X_test[protected_att] == 1) & (X_test['credit_amount'] == 0)], X_test[(X_test[protected_att] == 1) & (X_test['credit_amount'] == 1)]\n",
    "      \n",
    "    # confusion matrix for minority, majority\n",
    "    conf_matrix_min, conf_matrix_maj = confusion_matrix_scorer(y_test_min,y_pred_min), confusion_matrix_scorer(y_test_maj,y_pred_maj)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # predicted outcomes for the six groups\n",
    "    y_pred_A0_X0, y_pred_A0_X1,y_pred_A1_X0, y_pred_A1_X1 = model.predict(X_test_min_X0), model.predict(X_test_min_X1), model.predict(X_test_maj_X0), model.predict(X_test_maj_X1)\n",
    "\n",
    "    # computing fairness metrics\n",
    "    np_sp_min1.append(Statistical_parity(y_pred_min))\n",
    "    np_sp_maj1.append(Statistical_parity(y_pred_maj))\n",
    "    np_sd.append(Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)))\n",
    "    np_eo_min1.append(Equal_opportunity(conf_matrix_min))\n",
    "    np_eo_maj1.append(Equal_opportunity(conf_matrix_maj))\n",
    "    np_eod.append(Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)))    \n",
    "    ndp_csp_minX0.append(Statistical_parity(y_pred_A0_X0))\n",
    "    ndp_csp_majX0.append(Statistical_parity(y_pred_A1_X0))\n",
    "    np_csd_X0.append(Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)))\n",
    "    ndp_csp_minX1.append(Statistical_parity(y_pred_A0_X1))\n",
    "    ndp_csp_majX1.append(Statistical_parity(y_pred_A1_X1))  \n",
    "    np_csd_X1.append(Metric_disparity(Statistical_parity(y_pred_A1_X1), Statistical_parity(y_pred_A0_X1)))\n",
    "    acc.append(accuracy)\n",
    "    #writing the results to the csv file\n",
    "    write_to_csv(setting,dataset,[str(seed), Statistical_parity(y_pred_maj),Statistical_parity(y_pred_min),Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)),Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min), Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)),Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0),Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)), Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1),Metric_disparity(Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1)),accuracy])\n",
    "\n",
    "print('That took {} seconds'.format(time.time() - starttime)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDP setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Setting 1: Local DP: only the sensitive feature is obfuscated =========\n",
      "\n",
      "50\n",
      "16\n",
      "8\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0.5\n",
      "That took 939.5373477935791 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n========= Setting 1: Local DP: only the sensitive feature is obfuscated =========\\n\")\n",
    "\n",
    "#folder_name of the results\n",
    "setting = 'sLDP'\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "# write head of csv file\n",
    "write_to_csv(setting,dataset,header_ldp)\n",
    "\n",
    "df_cp = copy.deepcopy(df)\n",
    "\n",
    "\n",
    "sldp_sp_min1, sldp_sp_maj1, sldp_sd, sd_std  = [], [], [], []\n",
    "sldp_csp_minX0, sldp_csp_majX0, sldp_csd_X0, csd_X0_std, sldp_csp_minX1, sldp_csp_majX1, sldp_csd_X1, csd_X1_std= [], [] , [], [], [],[], [], []\n",
    "sldp_oa_min1, sldp_oa_maj1, sldp_oad, oad_std = [], [], [], []\n",
    "sldp_eo_min1, sldp_eo_maj1, sldp_eod, eod_std, acc = [], [], [], [], [] \n",
    "\n",
    "for epsilon in lst_eps:\n",
    "    print(epsilon)\n",
    "    \n",
    "    ldp_sp_min, ldp_sp_maj, ldp_sd = [], [], []\n",
    "    ldp_csp_minX0, ldp_csp_majX0, ldp_csd_X0, ldp_csp_minX1, ldp_csp_majX1,ldp_csd_X1 = [], [],[], [], [], []\n",
    "    ldp_oa_min, ldp_oa_maj, ldp_oad  = [], [], []\n",
    "    ldp_eo_min, ldp_eo_maj, ldp_eod, acc  = [], [], [], []\n",
    "    \n",
    "    for seed in range(nb_seed):\n",
    "        #np.random.seed(seed)\n",
    "\n",
    "        # Preparing X and y using pandas\n",
    "        X = copy.deepcopy(df_cp.drop(target, axis=1))\n",
    "        y = copy.deepcopy(df_cp[target])\n",
    "\n",
    "        # Train test splitting\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True, stratify=y, random_state=seed)\n",
    "\n",
    "        # Attribute's domain size\n",
    "        k = len(set(X[protected_att]))\n",
    "\n",
    "        # Applying GRR to the protected attribute of the training set\n",
    "        X_train[protected_att] = X_train[protected_att].apply(lambda x: GRR_Client(x, k, epsilon))\n",
    "        \n",
    "        # instantiate and train model\n",
    "        model = RandomForestClassifier(n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test) # prediction of the actual samples\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # retrieving minority, majority from the test set\n",
    "        X_test_min, X_test_maj = X_test[X_test[protected_att] == 0], X_test[X_test[protected_att] == 1]\n",
    "\n",
    "        # predicted outcomes for minority, majority\n",
    "        y_pred_min, y_pred_maj = model.predict(X_test_min), model.predict(X_test_maj)\n",
    "\n",
    "        indices_min, indices_maj = X_test_min.index, X_test_maj.index\n",
    "        y_test_min, y_test_maj = y_test.get(key = indices_min), y_test.get(key = indices_maj)\n",
    "        \n",
    "        \n",
    "        # Needed for the computation of Cond.Stat.Disp\n",
    "            \n",
    "        # retrieving four groups: A=0_X=0, A0_X=1, A1_X=0, A1_X=1 from the test set\n",
    "\n",
    "        X_test_min_X0, X_test_min_X1, X_test_maj_X0, X_test_maj_X1 = X_test[(X_test[protected_att] == 0) & (X_test['credit_amount'] == 0)], X_test[(X_test[protected_att] == 0) & (X_test['credit_amount'] == 1)], X_test[(X_test[protected_att] == 1) & (X_test['credit_amount'] == 0)], X_test[(X_test[protected_att] == 1) & (X_test['credit_amount'] == 1)]\n",
    "        \n",
    "        # confusion matrix for minority, majority\n",
    "        conf_matrix_min, conf_matrix_maj = confusion_matrix_scorer(y_test_min,y_pred_min), confusion_matrix_scorer(y_test_maj,y_pred_maj)\n",
    "\n",
    "        \n",
    "        # predicted outcomes for the four groups\n",
    "        y_pred_A0_X0, y_pred_A0_X1,y_pred_A1_X0, y_pred_A1_X1 = model.predict(X_test_min_X0), model.predict(X_test_min_X1), model.predict(X_test_maj_X0), model.predict(X_test_maj_X1)\n",
    "\n",
    "        # computing fairness metrics with obfuscated A\n",
    "        ldp_sp_min.append(Statistical_parity(y_pred_min))\n",
    "        ldp_sp_maj.append(Statistical_parity(y_pred_maj))\n",
    "        ldp_sd.append(Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)))\n",
    "        \n",
    "        ldp_eo_min.append(Equal_opportunity(conf_matrix_min))   \n",
    "        ldp_eo_maj.append(Equal_opportunity(conf_matrix_maj))\n",
    "        ldp_eod.append(Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)))\n",
    "        \n",
    "        ldp_csp_minX0.append(Statistical_parity(y_pred_A0_X0))\n",
    "        ldp_csp_majX0.append(Statistical_parity(y_pred_A1_X0))\n",
    "        ldp_csd_X0.append(Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)))\n",
    "        \n",
    "        ldp_csp_minX1.append(Statistical_parity(y_pred_A0_X1))\n",
    "        ldp_csp_majX1.append(Statistical_parity(y_pred_A1_X1))\n",
    "        ldp_csd_X1.append(Metric_disparity(Statistical_parity(y_pred_A1_X1), Statistical_parity(y_pred_A0_X1)))\n",
    "        write_to_csv(setting,dataset,[str(seed), str(epsilon), Statistical_parity(y_pred_maj),Statistical_parity(y_pred_min),Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)),Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min), Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)),Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0),Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)), Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1),Metric_disparity(Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1)),accuracy])\n",
    "    \n",
    "    sldp_sp_min1.append(np.mean(ldp_sp_min))\n",
    "    sldp_sp_maj1.append(np.mean(ldp_sp_maj))\n",
    "    sldp_sd.append(np.mean(ldp_sd))\n",
    "    sd_std.append(np.std(sldp_sd))\n",
    "    sldp_csp_minX0.append(np.mean(ldp_csp_minX0))\n",
    "    sldp_csp_majX0.append(np.mean(ldp_csp_majX0))\n",
    "    sldp_csd_X0.append(np.mean(ldp_csd_X0))\n",
    "    csd_X0_std.append(np.std(sldp_csd_X0))\n",
    "    sldp_csp_minX1.append(np.mean(ldp_csp_minX1))\n",
    "    sldp_csp_majX1.append(np.mean(ldp_csp_majX1))\n",
    "    sldp_csd_X1.append(np.mean(ldp_csd_X1))\n",
    "    csd_X1_std.append(np.std(sldp_csd_X1))\n",
    "    sldp_eo_min1.append(np.mean(ldp_eo_min))\n",
    "    sldp_eo_maj1.append(np.mean(ldp_eo_maj))\n",
    "    sldp_eod.append(np.mean(ldp_eod))\n",
    "    eod_std.append(np.std(sldp_eod))\n",
    "        #writing the results to the csv file\n",
    "        #write_to_csv(setting,dataset,[str(seed), str(epsilon), Statistical_parity(y_pred_maj),Statistical_parity(y_pred_min),Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)),Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min), Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)),Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0),Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)), Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1),Metric_disparity(Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1))])\n",
    "print('That took {} seconds'.format(time.time() - starttime)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
