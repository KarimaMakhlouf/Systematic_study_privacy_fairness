{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "# LDP import\n",
    "from multi_freq_ldpy.pure_frequency_oracles.GRR import GRR_Client\n",
    "from GRR import GRR_Client\n",
    "# Fairness imports\n",
    "from GroupFairnessNotions import confusion_matrix_scorer, Statistical_parity, Metric_disparity, Equal_opportunity, Predictive_equality, Treatment_equality, Overall_accuracy, Predictive_rate_parity, CSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_seed = 100\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "\n",
    "# Reading dataset\n",
    "dataset = 'compas_good_outcome' \n",
    "# Target attribute\n",
    "target = 'v_decile_score' \n",
    "\n",
    "# Protected attribute \n",
    "protected_att = 'race'\n",
    "\n",
    "\n",
    "# Folder where results are saved as csv files\n",
    "results_path = 'Results/Accuracy/'\n",
    "# Fariness metrics and info no privacy results\n",
    "header_nldp = [\"Seed_num\",\"SP_maj\", \"SP_min\", \"SPD\",\"EO_maj\",\"EO_min\",\"EOD\",\"CSP_X0_maj\", \"CSP_X0_min\", \"CSD_X0\",\"CSP_X1_maj\", \"CSP_X1_min\", \"CSD_X1\",\"Accuracy\"]\n",
    "# Fariness metrics and info for privacy settings\n",
    "header_ldp = [\"Seed_num\",\"epsilon\",\"SP_maj\", \"SP_min\", \"SPD\",\"EO_maj\",\"EO_min\",\"EOD\",\"CSP_X0_maj\", \"CSP_X0_min\", \"CSD_X0\",\"CSP_X1_maj\", \"CSP_X1_min\", \"CSD_X1\",\"Accuracy\"]\n",
    "\n",
    "# Epsilon values for privacy\n",
    "lst_eps = [50,16,8,5,4,3,2,1,0.5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to csv function for saving the results\n",
    "def write_to_csv(setting,dataset,header):\n",
    "    with open(results_path + dataset + '_'+ setting +'_results.csv', mode='a', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)    \n",
    "        writer.writerow(header)   \n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>v_decile_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5915 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  race  age_cat  priors_count  v_decile_score\n",
       "0       1     0        0             0               1\n",
       "1       1     0        2             1               0\n",
       "2       1     1        0             1               0\n",
       "3       0     1        0             0               1\n",
       "4       1     1        2             0               0\n",
       "...   ...   ...      ...           ...             ...\n",
       "5910    1     0        0             0               0\n",
       "5911    1     0        2             0               0\n",
       "5912    1     0        2             0               0\n",
       "5913    1     0        2             0               0\n",
       "5914    0     0        0             1               0\n",
       "\n",
       "[5915 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/Real_data/Compas/' + dataset + '.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0_X0_Y0: 0.24970414201183433\n",
      "\n",
      "A0_X1_Y0: 0.25528317836010145\n",
      "\n",
      "A1_X0_Y0: 0.15316990701606087\n",
      "\n",
      "A1_X1_Y0: 0.09873203719357565\n",
      "\n",
      "A0_X0_Y1: 0.0610312764158918\n",
      "\n",
      "A0_X1_Y1: 0.03195266272189349\n",
      "\n",
      "A1_X0_Y1: 0.11868131868131868\n",
      "\n",
      "A1_X1_Y1: 0.03144547759932375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A0_X0_Y0 = len(df[(df['race'] == 0) & (df['priors_count'] == 0) & (df['v_decile_score'] == 0)])\n",
    "A0_X1_Y0 = len(df[(df['race'] == 0) & (df['priors_count'] == 1) & (df['v_decile_score'] == 0)])\n",
    "\n",
    "A1_X0_Y0 = len(df[(df['race'] == 1) & (df['priors_count'] == 0) & (df['v_decile_score'] == 0)])\n",
    "A1_X1_Y0 = len(df[(df['race'] == 1) & (df['priors_count'] == 1) & (df['v_decile_score'] == 0)])\n",
    "\n",
    "A0_X0_Y1 = len(df[(df['race'] == 0) & (df['priors_count'] == 0) & (df['v_decile_score'] == 1)])\n",
    "A0_X1_Y1 = len(df[(df['race'] == 0) & (df['priors_count'] == 1) & (df['v_decile_score'] == 1)])\n",
    "\n",
    "A1_X0_Y1 = len(df[(df['race'] == 1) & (df['priors_count'] == 0) & (df['v_decile_score'] == 1)])\n",
    "A1_X1_Y1 = len(df[(df['race'] == 1) & (df['priors_count'] == 1) & (df['v_decile_score'] == 1)])\n",
    "\n",
    "print(f'A0_X0_Y0: {A0_X0_Y0/5915}\\n') \n",
    "print(f'A0_X1_Y0: {A0_X1_Y0/5915}\\n') \n",
    "print(f'A1_X0_Y0: {A1_X0_Y0/5915}\\n') \n",
    "print(f'A1_X1_Y0: {A1_X1_Y0/5915}\\n') \n",
    "print(f'A0_X0_Y1: {A0_X0_Y1/5915}\\n') \n",
    "print(f'A0_X1_Y1: {A0_X1_Y1/5915}\\n') \n",
    "print(f'A1_X0_Y1: {A1_X0_Y1/5915}\\n') \n",
    "print(f'A1_X1_Y1: {A1_X1_Y1/5915}\\n')\n",
    "\n",
    "\n",
    "l = [A0_X0_Y0,A0_X1_Y0,A1_X0_Y0,A1_X1_Y0,A0_X0_Y1,A0_X1_Y1,A1_X0_Y1,A1_X1_Y1]\n",
    "x = sum(l)/5915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for no privacy setting (baseline setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "That took 107.86753416061401 seconds\n"
     ]
    }
   ],
   "source": [
    "#folder_name of the results\n",
    "setting = 'NoLDP3'\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "# write head of csv file\n",
    "write_to_csv(setting,dataset,header_nldp)\n",
    "\n",
    "df_cp = copy.deepcopy(df)\n",
    "\n",
    "\n",
    "np_sp_min1, np_sp_maj1, np_sd = [], [], []\n",
    "ndp_csp_minX0, ndp_csp_majX0, np_csd_X0, ndp_csp_minX1, ndp_csp_majX1, np_csd_X1 = [], [] ,[] , [],[], []\n",
    "np_eo_min1, np_eo_maj1, np_eod, acc = [], [], [], []\n",
    "\n",
    "\n",
    "for seed in range(nb_seed):\n",
    "    print(seed)\n",
    "    np.random.seed(seed) # for reproducibility\n",
    "    \n",
    "    # Use original datasets\n",
    "    X = copy.deepcopy(df_cp.drop(target, axis=1))\n",
    "    y = copy.deepcopy(df_cp[target])\n",
    "\n",
    "    # Train test splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True, stratify=y, random_state=seed)\n",
    "    \n",
    "    # instantiate and train model\n",
    "    model = RandomForestClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # accuracy\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "    # retrieving minority, majority from the test set\n",
    "    X_test_min, X_test_maj = X_test[X_test[protected_att] == 0], X_test[X_test[protected_att] == 1]\n",
    "\n",
    "    # predicted outcomes for minority, majority\n",
    "    y_pred_min, y_pred_maj = model.predict(X_test_min), model.predict(X_test_maj)\n",
    "\n",
    "    indices_min, indices_maj = X_test_min.index, X_test_maj.index\n",
    "    y_test_min, y_test_maj = y_test.get(key = indices_min), y_test.get(key = indices_maj)\n",
    "    \n",
    "    # Needed for the computation of Cond.Stat.Disp\n",
    "            \n",
    "    # retrieving four groups: A=0_X=0, A0_X=1, A1_X=0, A1_X=1 from the test set\n",
    "\n",
    "    X_test_min_X0, X_test_min_X1, X_test_maj_X0, X_test_maj_X1 = X_test[(X_test[protected_att] == 0) & (X_test['priors_count'] == 0)], X_test[(X_test[protected_att] == 0) & (X_test['priors_count'] == 1)], X_test[(X_test[protected_att] == 1) & (X_test['priors_count'] == 0)], X_test[(X_test[protected_att] == 1) & (X_test['priors_count'] == 1)]\n",
    "      \n",
    "    # confusion matrix for minority, majority\n",
    "    conf_matrix_min, conf_matrix_maj = confusion_matrix_scorer(y_test_min,y_pred_min), confusion_matrix_scorer(y_test_maj,y_pred_maj)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # predicted outcomes for the six groups\n",
    "    y_pred_A0_X0, y_pred_A0_X1,y_pred_A1_X0, y_pred_A1_X1 = model.predict(X_test_min_X0), model.predict(X_test_min_X1), model.predict(X_test_maj_X0), model.predict(X_test_maj_X1)\n",
    "\n",
    "    # computing fairness metrics\n",
    "    np_sp_min1.append(Statistical_parity(y_pred_min))\n",
    "    np_sp_maj1.append(Statistical_parity(y_pred_maj))\n",
    "    np_sd.append(Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)))\n",
    "    np_eo_min1.append(Equal_opportunity(conf_matrix_min))\n",
    "    np_eo_maj1.append(Equal_opportunity(conf_matrix_maj))\n",
    "    np_eod.append(Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)))    \n",
    "    ndp_csp_minX0.append(Statistical_parity(y_pred_A0_X0))\n",
    "    ndp_csp_majX0.append(Statistical_parity(y_pred_A1_X0))\n",
    "    np_csd_X0.append(Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)))\n",
    "    ndp_csp_minX1.append(Statistical_parity(y_pred_A0_X1))\n",
    "    ndp_csp_majX1.append(Statistical_parity(y_pred_A1_X1))  \n",
    "    np_csd_X1.append(Metric_disparity(Statistical_parity(y_pred_A1_X1), Statistical_parity(y_pred_A0_X1)))\n",
    "    acc.append(accuracy)\n",
    "    #writing the results to the csv file\n",
    "    write_to_csv(setting,dataset,[str(seed), Statistical_parity(y_pred_maj),Statistical_parity(y_pred_min),Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)),Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min), Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)),Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0),Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)), Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1),Metric_disparity(Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1)), accuracy])\n",
    "\n",
    "print('That took {} seconds'.format(time.time() - starttime)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDP setting 1: Only the protected attribute is obfuscated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Setting 1: Local DP: only the sensitive feature is obfuscated =========\n",
      "\n",
      "50\n",
      "16\n",
      "8\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0.5\n",
      "That took 1025.6451888084412 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n========= Setting 1: Local DP: only the sensitive feature is obfuscated =========\\n\")\n",
    "\n",
    "#folder_name of the results\n",
    "setting = 'sLDP3'\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "# write head of csv file\n",
    "write_to_csv(setting,dataset,header_ldp)\n",
    "\n",
    "df_cp = copy.deepcopy(df)\n",
    "\n",
    "\n",
    "sldp_sp_min1, sldp_sp_maj1, sldp_sd, sd_std  = [], [], [], []\n",
    "sldp_csp_minX0, sldp_csp_majX0, sldp_csd_X0, csd_X0_std, sldp_csp_minX1, sldp_csp_majX1, sldp_csd_X1, csd_X1_std= [], [] , [], [], [],[], [], []\n",
    "sldp_oa_min1, sldp_oa_maj1, sldp_oad, oad_std = [], [], [], []\n",
    "sldp_eo_min1, sldp_eo_maj1, sldp_eod, eod_std, acc = [], [], [], [], []\n",
    "\n",
    "\n",
    "for epsilon in lst_eps:\n",
    "    print(epsilon)\n",
    "    \n",
    "    ldp_sp_min, ldp_sp_maj, ldp_sd = [], [], []\n",
    "    ldp_csp_minX0, ldp_csp_majX0, ldp_csd_X0, ldp_csp_minX1, ldp_csp_majX1,ldp_csd_X1 = [], [],[], [], [], []\n",
    "    ldp_oa_min, ldp_oa_maj, ldp_oad  = [], [], []\n",
    "    ldp_eo_min, ldp_eo_maj, ldp_eod, acc = [], [], [], []\n",
    "    \n",
    "    for seed in range(nb_seed):\n",
    "        #np.random.seed(seed)\n",
    "\n",
    "        # Preparing X and y using pandas\n",
    "        X = copy.deepcopy(df_cp.drop(target, axis=1))\n",
    "        y = copy.deepcopy(df_cp[target])\n",
    "\n",
    "        # Train test splitting\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True, stratify=y, random_state=seed)\n",
    "\n",
    "        # Attribute's domain size\n",
    "        k = len(set(X[protected_att]))\n",
    "\n",
    "        # Applying GRR to the protected attribute of the training set\n",
    "        X_train[protected_att] = X_train[protected_att].apply(lambda x: GRR_Client(x, k, epsilon))\n",
    "        \n",
    "        # instantiate and train model\n",
    "        model = RandomForestClassifier(n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test) # prediction of the actual samples\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # retrieving minority, majority from the test set\n",
    "        X_test_min, X_test_maj = X_test[X_test[protected_att] == 0], X_test[X_test[protected_att] == 1]\n",
    "\n",
    "        # predicted outcomes for minority, majority\n",
    "        y_pred_min, y_pred_maj = model.predict(X_test_min), model.predict(X_test_maj)\n",
    "\n",
    "        indices_min, indices_maj = X_test_min.index, X_test_maj.index\n",
    "        y_test_min, y_test_maj = y_test.get(key = indices_min), y_test.get(key = indices_maj)\n",
    "        \n",
    "        \n",
    "        # Needed for the computation of Cond.Stat.Disp\n",
    "            \n",
    "        # retrieving four groups: A=0_X=0, A0_X=1, A1_X=0, A1_X=1 from the test set\n",
    "            \n",
    "        X_test_min_X0, X_test_min_X1, X_test_maj_X0, X_test_maj_X1 = X_test[(X_test[protected_att] == 0) & (X_test['priors_count'] == 0)], X_test[(X_test[protected_att] == 0) & (X_test['priors_count'] == 1)], X_test[(X_test[protected_att] == 1) & (X_test['priors_count'] == 0)], X_test[(X_test[protected_att] == 1) & (X_test['priors_count'] == 1)]\n",
    "        \n",
    "        # confusion matrix for minority, majority\n",
    "        conf_matrix_min, conf_matrix_maj = confusion_matrix_scorer(y_test_min,y_pred_min), confusion_matrix_scorer(y_test_maj,y_pred_maj)\n",
    "\n",
    "        \n",
    "        # predicted outcomes for the four groups\n",
    "        y_pred_A0_X0, y_pred_A0_X1,y_pred_A1_X0, y_pred_A1_X1 = model.predict(X_test_min_X0), model.predict(X_test_min_X1), model.predict(X_test_maj_X0), model.predict(X_test_maj_X1)\n",
    "\n",
    "        # computing fairness metrics with obfuscated A\n",
    "        ldp_sp_min.append(Statistical_parity(y_pred_min))\n",
    "        ldp_sp_maj.append(Statistical_parity(y_pred_maj))\n",
    "        ldp_sd.append(Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)))\n",
    "        \n",
    "        ldp_eo_min.append(Equal_opportunity(conf_matrix_min))   \n",
    "        ldp_eo_maj.append(Equal_opportunity(conf_matrix_maj))\n",
    "        ldp_eod.append(Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)))\n",
    "        \n",
    "        ldp_csp_minX0.append(Statistical_parity(y_pred_A0_X0))\n",
    "        ldp_csp_majX0.append(Statistical_parity(y_pred_A1_X0))\n",
    "        ldp_csd_X0.append(Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)))\n",
    "        \n",
    "        ldp_csp_minX1.append(Statistical_parity(y_pred_A0_X1))\n",
    "        ldp_csp_majX1.append(Statistical_parity(y_pred_A1_X1))\n",
    "        ldp_csd_X1.append(Metric_disparity(Statistical_parity(y_pred_A1_X1), Statistical_parity(y_pred_A0_X1)))\n",
    "        write_to_csv(setting,dataset,[str(seed), str(epsilon), Statistical_parity(y_pred_maj),Statistical_parity(y_pred_min),Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)),Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min), Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)),Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0),Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)), Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1),Metric_disparity(Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1)),accuracy])\n",
    "    \n",
    "    sldp_sp_min1.append(np.mean(ldp_sp_min))\n",
    "    sldp_sp_maj1.append(np.mean(ldp_sp_maj))\n",
    "    sldp_sd.append(np.mean(ldp_sd))\n",
    "    sd_std.append(np.std(sldp_sd))\n",
    "    sldp_csp_minX0.append(np.mean(ldp_csp_minX0))\n",
    "    sldp_csp_majX0.append(np.mean(ldp_csp_majX0))\n",
    "    sldp_csd_X0.append(np.mean(ldp_csd_X0))\n",
    "    csd_X0_std.append(np.std(sldp_csd_X0))\n",
    "    sldp_csp_minX1.append(np.mean(ldp_csp_minX1))\n",
    "    sldp_csp_majX1.append(np.mean(ldp_csp_majX1))\n",
    "    sldp_csd_X1.append(np.mean(ldp_csd_X1))\n",
    "    csd_X1_std.append(np.std(sldp_csd_X1))\n",
    "    sldp_eo_min1.append(np.mean(ldp_eo_min))\n",
    "    sldp_eo_maj1.append(np.mean(ldp_eo_maj))\n",
    "    sldp_eod.append(np.mean(ldp_eod))\n",
    "    eod_std.append(np.std(sldp_eod))\n",
    "        #writing the results to the csv file\n",
    "        #write_to_csv(setting,dataset,[str(seed), str(epsilon), Statistical_parity(y_pred_maj),Statistical_parity(y_pred_min),Metric_disparity(Statistical_parity(y_pred_maj), Statistical_parity(y_pred_min)),Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min), Metric_disparity(Equal_opportunity(conf_matrix_maj), Equal_opportunity(conf_matrix_min)),Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0),Metric_disparity(Statistical_parity(y_pred_A1_X0), Statistical_parity(y_pred_A0_X0)), Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1),Metric_disparity(Statistical_parity(y_pred_A1_X1),Statistical_parity(y_pred_A0_X1))])\n",
    "print('That took {} seconds'.format(time.time() - starttime)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
